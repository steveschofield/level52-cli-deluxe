"""
Local cache for exploit references (Metasploit + Exploit-DB).
"""

from __future__ import annotations

import csv
import json
import os
import re
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple


DEFAULT_CACHE_TTL_DAYS = 7
DEFAULT_CACHE_DIR = Path.home() / ".guardian" / "cache" / "exploits"
_SOURCE_CHECK_LOGGED = False
TOKEN_STOPWORDS = {
    "exploit",
    "vulnerability",
    "remote",
    "code",
    "execution",
    "authentication",
    "authorization",
    "bypass",
    "disclosure",
    "service",
    "server",
    "client",
    "unauthenticated",
}


def extract_cves(text: str) -> List[str]:
    if not text:
        return []
    matches = re.findall(r"\bCVE-\d{4}-\d{4,7}\b", text, re.IGNORECASE)
    uniq: List[str] = []
    for m in matches:
        normalized = m.upper()
        if normalized not in uniq:
            uniq.append(normalized)
    return uniq


def _tokenize(text: str) -> List[str]:
    if not text:
        return []
    tokens = re.findall(r"[a-z0-9]{4,}", text.lower())
    return [t for t in tokens if t not in TOKEN_STOPWORDS]


class ExploitCache:
    def __init__(self, config: Dict[str, Any], logger: Optional[Any] = None):
        cfg = (config or {}).get("exploits", {}) or {}
        self.enabled = bool(cfg.get("enabled", True))
        self.cache_dir = Path(cfg.get("cache_dir", DEFAULT_CACHE_DIR)).expanduser()
        self.cache_ttl_days = _safe_int(cfg.get("cache_ttl_days"), DEFAULT_CACHE_TTL_DAYS)
        self.exploitdb_path = (
            cfg.get("exploitdb_path")
            or os.getenv("GUARDIAN_EXPLOITDB_PATH")
            or os.getenv("EXPLOITDB_PATH")
        )
        self.metasploit_path = (
            cfg.get("metasploit_path")
            or os.getenv("GUARDIAN_METASPLOIT_PATH")
            or os.getenv("METASPLOIT_PATH")
        )
        self.enable_fuzzy_match = bool(cfg.get("enable_fuzzy_match", False))
        self.logger = logger
        self._log_source_preflight_once()

    def _log_source_preflight_once(self) -> None:
        """Log exploit source availability early so missing paths are obvious before reporting."""
        global _SOURCE_CHECK_LOGGED
        if _SOURCE_CHECK_LOGGED or not self.enabled:
            return
        _SOURCE_CHECK_LOGGED = True

        exploitdb_root = self._resolve_exploitdb_path()
        if not exploitdb_root:
            configured = self.exploitdb_path or "unset"
            _log(
                self.logger,
                "warning",
                "Exploit lookup: Exploit-DB source not found. "
                f"Set config `exploits.exploitdb_path` (current: {configured}).",
            )
        elif not (exploitdb_root / "files_exploits.csv").exists():
            _log(
                self.logger,
                "warning",
                "Exploit lookup: Exploit-DB path is present but missing "
                f"`files_exploits.csv`: {exploitdb_root}",
            )

        metasploit_root = self._resolve_metasploit_path()
        if not metasploit_root:
            configured = self.metasploit_path or "unset"
            _log(
                self.logger,
                "warning",
                "Exploit lookup: Metasploit source not found. "
                f"Set config `exploits.metasploit_path` (current: {configured}).",
            )
        elif not (metasploit_root / "modules" / "exploits").exists():
            _log(
                self.logger,
                "warning",
                "Exploit lookup: Metasploit path is present but missing "
                f"`modules/exploits`: {metasploit_root}",
            )

    def load_exploitdb(self) -> Tuple[List[Dict[str, Any]], Dict[str, Any]]:
        if not self.enabled:
            return [], {"state": "disabled"}

        cache_path = self.cache_dir / "exploitdb.json"
        cached = _load_cache(cache_path, self.cache_ttl_days)
        if cached:
            return cached.get("items", []), cached.get("status", {"state": "cache"})

        items, status = self._build_exploitdb()
        _write_cache(cache_path, items, status)
        return items, status

    def load_metasploit(self) -> Tuple[List[Dict[str, Any]], Dict[str, Any]]:
        if not self.enabled:
            return [], {"state": "disabled"}

        cache_path = self.cache_dir / "metasploit.json"
        cached = _load_cache(cache_path, self.cache_ttl_days)
        if cached:
            return cached.get("items", []), cached.get("status", {"state": "cache"})

        items, status = self._build_metasploit()
        _write_cache(cache_path, items, status)
        return items, status

    def _build_exploitdb(self) -> Tuple[List[Dict[str, Any]], Dict[str, Any]]:
        path = self._resolve_exploitdb_path()
        if not path:
            return [], {"state": "missing-source"}

        csv_path = path / "files_exploits.csv"
        if not csv_path.exists():
            return [], {"state": "missing-source", "source": str(path)}

        items: List[Dict[str, Any]] = []
        try:
            with open(csv_path, "r", encoding="utf-8", errors="replace", newline="") as handle:
                reader = csv.DictReader(handle)
                for row in reader:
                    description = row.get("description", "").strip()
                    item = {
                        "id": (row.get("id") or "").strip(),
                        "description": description,
                        "file": (row.get("file") or "").strip(),
                        "date": (row.get("date") or "").strip(),
                        "author": (row.get("author") or "").strip(),
                        "type": (row.get("type") or "").strip(),
                        "platform": (row.get("platform") or "").strip(),
                        "port": (row.get("port") or "").strip(),
                        "cves": extract_cves(description),
                    }
                    items.append(item)
        except Exception as exc:
            _log(self.logger, "warning", f"Exploit-DB cache build failed: {exc}")
            return [], {"state": "error", "error": str(exc)}

        return items, {"state": "built", "source": str(path), "count": len(items)}

    def _build_metasploit(self) -> Tuple[List[Dict[str, Any]], Dict[str, Any]]:
        path = self._resolve_metasploit_path()
        if not path:
            return [], {"state": "missing-source"}

        modules_path = path / "modules" / "exploits"
        if not modules_path.exists():
            return [], {"state": "missing-source", "source": str(path)}

        items: List[Dict[str, Any]] = []
        try:
            for rb_file in modules_path.rglob("*.rb"):
                text = rb_file.read_text(encoding="utf-8", errors="replace")
                name = _extract_msf_name(text) or rb_file.stem
                cves = extract_cves(text)
                module_rel = rb_file.relative_to(modules_path).as_posix()
                module_path = f"exploit/{module_rel[:-3]}" if module_rel.endswith(".rb") else f"exploit/{module_rel}"
                items.append(
                    {
                        "module": module_path,
                        "name": name,
                        "path": str(rb_file),
                        "cves": cves,
                    }
                )
        except Exception as exc:
            _log(self.logger, "warning", f"Metasploit cache build failed: {exc}")
            return [], {"state": "error", "error": str(exc)}

        return items, {"state": "built", "source": str(path), "count": len(items)}

    def _resolve_exploitdb_path(self) -> Optional[Path]:
        candidates = []
        if self.exploitdb_path:
            candidates.append(Path(self.exploitdb_path))
        candidates.extend(
            [
                Path("/usr/share/exploitdb"),
                Path("/opt/exploitdb"),
            ]
        )
        for candidate in candidates:
            if candidate.exists():
                return candidate
        return None

    def _resolve_metasploit_path(self) -> Optional[Path]:
        candidates = []
        if self.metasploit_path:
            candidates.append(Path(self.metasploit_path))
        candidates.extend(
            [
                Path("/usr/share/metasploit-framework"),
                Path("/opt/metasploit-framework"),
            ]
        )
        for candidate in candidates:
            if candidate.exists():
                return candidate
        return None


class ExploitLookup:
    def __init__(self, config: Dict[str, Any], logger: Optional[Any] = None):
        self.cache = ExploitCache(config, logger=logger)

    def lookup_findings(self, findings: List[Any]) -> Dict[str, Any]:
        exploitdb_items, exploitdb_status = self.cache.load_exploitdb()
        metasploit_items, metasploit_status = self.cache.load_metasploit()

        exploitdb_index = _index_by_cve(exploitdb_items)
        metasploit_index = _index_by_cve(metasploit_items)
        exploitdb_tokens = None
        metasploit_tokens = None
        if self.cache.enable_fuzzy_match:
            exploitdb_tokens = _build_token_index(exploitdb_items, key_field="id", text_field="description")
            metasploit_tokens = _build_token_index(metasploit_items, key_field="module", text_field="name")

        matches: Dict[str, Dict[str, Any]] = {}
        for finding in findings:
            text = " ".join([finding.title or "", finding.description or "", finding.evidence or ""])
            cves = extract_cves(text)

            edb_hits: List[Dict[str, Any]] = []
            msf_hits: List[Dict[str, Any]] = []
            if cves:
                edb_hits = _dedupe_exploitdb_hits(_collect_hits(exploitdb_index, cves))
                msf_hits = _dedupe_metasploit_hits(_collect_hits(metasploit_index, cves))
            elif self.cache.enable_fuzzy_match:
                tokens = _tokenize(text)
                if tokens and exploitdb_tokens:
                    edb_hits = _dedupe_exploitdb_hits(_fuzzy_hits(exploitdb_tokens, tokens, max_results=5))
                if tokens and metasploit_tokens:
                    msf_hits = _dedupe_metasploit_hits(_fuzzy_hits(metasploit_tokens, tokens, max_results=5))

            if edb_hits or msf_hits:
                matches[finding.id] = {
                    "cves": cves,
                    "exploitdb": edb_hits,
                    "metasploit": msf_hits,
                }

        return {
            "status": {
                "exploitdb": exploitdb_status,
                "metasploit": metasploit_status,
            },
            "matches": matches,
        }


def _index_by_cve(items: List[Dict[str, Any]]) -> Dict[str, List[Dict[str, Any]]]:
    index: Dict[str, List[Dict[str, Any]]] = {}
    for item in items:
        for cve in item.get("cves", []) or []:
            bucket = index.setdefault(cve.upper(), [])
            bucket.append(item)
    return index


def _build_token_index(
    items: List[Dict[str, Any]],
    *,
    key_field: str,
    text_field: str,
    max_tokens: int = 10,
) -> Dict[str, Dict[str, Any]]:
    index: Dict[str, List[str]] = {}
    item_map: Dict[str, Dict[str, Any]] = {}
    for item in items:
        key = item.get(key_field)
        text = item.get(text_field) or ""
        if not key or not text:
            continue
        item_map[key] = item
        tokens = _tokenize(text)[:max_tokens]
        for token in tokens:
            bucket = index.setdefault(token, [])
            if key not in bucket:
                bucket.append(key)
    return {"index": index, "items": item_map}


def _fuzzy_hits(
    token_index: Dict[str, Dict[str, Any]],
    tokens: List[str],
    *,
    min_hits: int = 2,
    max_results: int = 5,
) -> List[Dict[str, Any]]:
    index = token_index.get("index", {})
    items = token_index.get("items", {})
    scores: Dict[str, int] = {}
    for token in tokens:
        for key in index.get(token, []):
            scores[key] = scores.get(key, 0) + 1
    ranked = sorted(scores.items(), key=lambda kv: kv[1], reverse=True)
    hits: List[Dict[str, Any]] = []
    for key, score in ranked:
        if score < min_hits:
            continue
        item = items.get(key)
        if item:
            hits.append(item)
        if len(hits) >= max_results:
            break
    return hits


def _collect_hits(index: Dict[str, List[Dict[str, Any]]], cves: List[str]) -> List[Dict[str, Any]]:
    hits: List[Dict[str, Any]] = []
    for cve in cves:
        for item in index.get(cve.upper(), []):
            hits.append(item)
    return hits


def _dedupe_exploitdb_hits(items: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    seen = set()
    output = []
    for item in items:
        key = item.get("id") or item.get("file") or item.get("description")
        if key in seen:
            continue
        seen.add(key)
        output.append(
            {
                "id": item.get("id"),
                "description": item.get("description"),
                "url": _exploitdb_url(item.get("id")),
            }
        )
    return output


def _dedupe_metasploit_hits(items: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    seen = set()
    output = []
    for item in items:
        key = item.get("module") or item.get("name")
        if key in seen:
            continue
        seen.add(key)
        output.append(
            {
                "module": item.get("module"),
                "name": item.get("name"),
                "url": _metasploit_url(item.get("module")),
            }
        )
    return output


def _exploitdb_url(exploit_id: Optional[str]) -> Optional[str]:
    if not exploit_id:
        return None
    return f"https://www.exploit-db.com/exploits/{exploit_id}"


def _metasploit_url(module_path: Optional[str]) -> Optional[str]:
    if not module_path:
        return None
    return f"https://www.rapid7.com/db/modules/{module_path}"


def _extract_msf_name(text: str) -> Optional[str]:
    match = re.search(r"['\"]Name['\"]\s*=>\s*['\"]([^'\"]+)['\"]", text)
    if match:
        return match.group(1).strip()
    return None


def _load_cache(path: Path, ttl_days: int) -> Optional[Dict[str, Any]]:
    if not path.exists():
        return None
    if ttl_days > 0:
        max_age = ttl_days * 86400
        age = (datetime.now().timestamp() - path.stat().st_mtime)
        if age > max_age:
            return None

    try:
        with open(path, "r", encoding="utf-8") as handle:
            return json.load(handle)
    except Exception:
        return None


def _write_cache(path: Path, items: List[Dict[str, Any]], status: Dict[str, Any]) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)
    payload = {
        "updated_at": datetime.now().isoformat(),
        "items": items,
        "status": status,
    }
    with open(path, "w", encoding="utf-8") as handle:
        json.dump(payload, handle, indent=2)


def _safe_int(value: Any, fallback: int) -> int:
    try:
        return int(value)
    except Exception:
        return fallback


def _log(logger: Optional[Any], level: str, message: str) -> None:
    if not logger:
        return
    try:
        getattr(logger, level)(message)
    except Exception:
        pass
